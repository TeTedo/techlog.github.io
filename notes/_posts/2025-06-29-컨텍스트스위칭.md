---
title: "컨텍스트 스위칭 이해"
date: 2025-06-29
categories: [운영체제, 동시성, 시스템]
tags: [컨텍스트스위칭, 프로세스, 스레드, 캐시, TLB, 스케줄러, OS, 동시성]
---

# 컨텍스트 스위칭

## 목차

1. [컨텍스트란?](#컨텍스트란)
2. [컨텍스트 스위칭이란?](#컨텍스트-스위칭이란)
3. [프로세스 vs 스레드 전환](#프로세스-vs-스레드-전환)
4. [스레드 전환이 더 빠른 이유](#스레드-전환이-더-빠른-이유)
5. [커널 모드에서의 동작](#커널-모드에서의-동작)
6. [캐시와 TLB의 영향](#캐시와-tlb의-영향)
7. [조금 더 ](#조금-더)
   - 사용자 vs 커널 스레드
   - TLB 최적화 기법
   - 스레드 풀 전략
   - 리눅스 스케줄러
   - NUMA와 멀티코어
   - 최적화 개발 패턴

## 컨텍스트란?

- CPU가 현재 실행 중인 **프로세스 또는 스레드의 상태 정보**
- 포함 요소:
  - 일반 레지스터 (RAX, RBX 등)
  - 스택 포인터(SP), 프로그램 카운터(PC)
  - 플래그, MMU 정보, TLB 캐시
  - 커널 구조체 정보 (예: `task_struct`)

## 컨텍스트 스위칭이란?

- **CPU 실행 대상 전환**: 이전 실행 단위의 컨텍스트 저장 → 다음 대상의 컨텍스트 복원
- 발생 시점:
  - 타임 슬라이스 만료
  - 시스템 콜/인터럽트
  - I/O 블로킹 발생
- 오버헤드 발생: 저장/복원 작업 + 캐시/TLB 영향

## 프로세스 vs 스레드 전환

| 항목      | 프로세스 전환 | 스레드 전환 |
| --------- | ------------- | ----------- |
| 주소 공간 | 서로 다름     | 동일        |
| MMU 변경  | 필요함        | 불필요      |
| TLB Flush | 발생          | 없음        |
| 캐시 유지 | 어려움        | 가능        |
| 속도      | 느림          | 빠름        |

## 스레드 전환이 빠른 이유

- 주소 공간 공유 → 페이지 테이블 불변
- TLB(주소 변환 캐시) 유지 가능
- 메모리 구조/캐시 재사용 용이
- 레지스터만 저장/복원 → 저비용

## 커널 모드에서의 동작

1. 유저 → 커널 전환 (예: 인터럽트, syscall)
2. 현재 컨텍스트 저장
3. 스케줄러가 다음 태스크 결정
4. 새로운 컨텍스트 복원
5. 유저 모드 복귀

> 스케줄러는 리눅스의 경우 `schedule()`, `context_switch()` 함수 등에서 동작

## 캐시와 TLB의 영향

### CPU 캐시

- CPU는 주 기억장치(RAM)보다 훨씬 빠른 **고속 메모리**를 계층적으로 보유하고 있음
- 이를 **캐시(Cache)**라고 하며, 계층은 일반적으로 다음과 같이 구성됨:

| 캐시 계층 | 위치                   | 용량    | 접근 속도                  |
| --------- | ---------------------- | ------- | -------------------------- |
| L1 Cache  | 각 CPU 코어 내부       | 수십 KB | 가장 빠름                  |
| L2 Cache  | 각 코어 내부 또는 공유 | 수백 KB | L1보다 느림                |
| L3 Cache  | 전체 CPU 공유          | 수 MB   | 가장 느림 (RAM보다는 빠름) |

- L1/L2/L3 캐시에 실행 중 데이터 저장
- **컨텍스트 전환 시 다른 프로세스 데이터로 오염(Cache Pollution)** 발생
  - 프로세스가 전환되면, 새 프로세스는 **이전 프로세스가 사용하던 캐시를 덮어쓰거나 무효화**함

### TLB

- 현대 운영체제는 **가상 주소(Virtual Address)**를 사용
- CPU는 가상 주소 → 물리 주소 변환을 위해 **페이지 테이블(Page Table)**을 사용
- 변환 속도 향상을 위해 페이지 테이블의 일부를 캐시한 것이 **TLB**임

### 1. TLB 컨텍스트 스위칭 시 영향

- 각 프로세스는 **고유의 페이지 테이블**을 가짐
- 프로세스가 전환되면 해당 TLB 내용이 **다른 주소 공간과 일치하지 않음**
  - → **TLB flush(무효화)**가 발생
- 변환 캐시를 다시 채우기 위한 **페이지 테이블 접근 → 지연**

> 스레드는 주소 공간 공유 → TLB 유지 가능

## 조금 더

### 1. 사용자 수준 스레드 vs 커널 스레드

| 구분          | User-Level Thread        | Kernel-Level Thread |
| ------------- | ------------------------ | ------------------- |
| 제어 주체     | 사용자 공간 (라이브러리) | OS 커널             |
| 커널 개입     | 없음                     | 있음                |
| 시스템 콜 시  | 전체 블로킹 가능성       | 독립 처리           |
| 멀티코어 활용 | 불가                     | 가능                |

> 예: Go의 goroutine = ULT, Java/Kotlin의 Thread = KLT

---

### 2. TLB 최적화 기법

- **ASID(Address Space ID)**: TLB 엔트리에 프로세스 식별자 포함 → flush 회피
- **Huge Pages 사용**: 매핑 수 줄여 TLB 압축
- **Global page marking**: 자주 쓰는 커널 페이지는 TLB 유지

---

### 3. 스레드 풀 전략

- **스레드를 미리 만들어두고(Task 발생 시 즉시 사용)**, 작업이 끝난 후에도 재사용 가능한 구조
- 즉, 스레드를 **필요할 때마다 생성하고 파괴하는 오버헤드를 줄이기 위한 기술**

---

#### 1. 왜 사용하는가?

| 문제점                        | 해결                             |
| ----------------------------- | -------------------------------- |
| 스레드 생성/소멸 비용 큼      | 미리 생성 후 재사용              |
| 동시 요청 폭증 시 리소스 고갈 | 풀 크기로 제한 가능              |
| 캐시 미스 증가                | 바운드 스레드로 캐시 친화성 유지 |
| context switch 증가           | 스레드 재사용으로 전환 비용 감소 |

---

#### 2. 스레드 풀 구조

```text
         +----------------------+
         |     작업 큐(Task)     |
         +----------+-----------+
                    |
            +-------▼--------+
            |   스레드 풀    |
            |  (고정된 수)   |
            +---+---+---+----+
                |   |   |
           +----+   |   +----+
           |        ▼        |
       Worker1   Worker2   WorkerN
           |        |        |
        실행 중   대기 중   실행 중
```

#### 3. 스레드 풀 전략

#### Work-Stealing 큐

• 각 워커가 자신의 작업 큐를 가짐
• 자신의 큐가 비면 다른 워커의 큐에서 작업을 훔쳐옴
• 병렬성 확보 + 부하 분산

#### 바운드 스레드 (CPU Affinity)

• 스레드를 **특정 CPU에 고정(binding)**하여 캐시 일관성을 유지
• CPU 캐시 재활용율(히트율) 증가 → 성능 향상

#### 동적 확장 (Elastic Pool)

• 부하가 증가하면 스레드를 늘리고, 감소하면 줄임
• Java의 ThreadPoolExecutor, Go의 runtime.GOMAXPROCS 등이 이 방식 활용

---

### 4. 리눅스 스케줄러 분석

- CFS(Completely Fair Scheduler)
  - 가상 실행 시간 기반 우선순위
  - `task_struct.vruntime` 기반 선점
- 분석 도구:
  ```bash
  perf stat -e context-switches ./app
  strace -T -e trace=read ./app
  ```
